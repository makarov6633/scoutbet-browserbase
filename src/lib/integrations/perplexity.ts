/**
 * Perplexity AI Integration - Sistema de IA avan√ßado
 * Baseado na documenta√ß√£o oficial do Perplexity AI Sonar
 */

export interface PerplexityMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface PerplexityRequest {
  model: 'sonar' | 'sonar-small' | 'mixtral-8x7b-instruct' | 'codellama-34b-instruct'
  messages: PerplexityMessage[]
  max_tokens?: number
  temperature?: number
  top_p?: number
  top_k?: number
  presence_penalty?: number
  frequency_penalty?: number
  return_citations?: boolean
  return_images?: boolean
  return_related_questions?: boolean
}

export interface PerplexityResponse {
  id: string
  model: string
  created: number
  object: string
  choices: Array<{
    index: number
    message: {
      role: string
      content: string
    }
    finish_reason: string
  }>
  usage: {
    prompt_tokens: number
    completion_tokens: number
    total_tokens: number
  }
}

export interface PerplexityError {
  error: {
    message: string
    type: string
    code: string
  }
}

export class PerplexityAIIntegration {
  private apiKey: string
  private baseUrl = 'https://api.perplexity.ai'
  private defaultModel = 'sonar'

  constructor() {
    this.apiKey = process.env.PERPLEXITY_API_KEY || ''
    if (!this.apiKey) {
      throw new Error('PERPLEXITY_API_KEY n√£o configurada')
    }
  }

  /**
   * Chamar API da Perplexity
   */
  async callAPI(request: PerplexityRequest): Promise<PerplexityResponse> {
    try {
      console.log('üß† [PERPLEXITY] Fazendo chamada para API...')

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: request.model || this.defaultModel,
          messages: request.messages,
          max_tokens: request.max_tokens || 1000,
          temperature: request.temperature || 0.3,
          top_p: request.top_p || 0.9,
          top_k: request.top_k || 40,
          presence_penalty: request.presence_penalty || 0,
          frequency_penalty: request.frequency_penalty || 0,
          return_citations: request.return_citations || false,
          return_images: request.return_images || false,
          return_related_questions: request.return_related_questions || false
        }),
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå [PERPLEXITY] API error:', response.status, errorText)
        throw new Error(`Perplexity API error: ${response.status} - ${errorText}`)
      }

      const data: PerplexityResponse = await response.json()
      console.log('‚úÖ [PERPLEXITY] Resposta recebida com sucesso')
      
      return data
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na chamada:', error)
      throw error
    }
  }

  /**
   * Interpretar inten√ß√£o do usu√°rio
   */
  async interpretUserIntent(userMessage: string): Promise<{
    tipo_consulta: string
    query: string
    explicacao: string
    confidence: number
  }> {
    const prompt = `Voc√™ √© um assistente especializado em classificar consultas de apostas esportivas. Analise a mensagem do usu√°rio e retorne em JSON:

{
  "tipo_consulta": "odds_lookup|arbitrage_search|team_analysis|predictions|value_betting|statistical_analysis|xg_analysis|live_scores|tipster_analysis|general",
  "query": "query otimizada para busca",
  "explicacao": "breve explica√ß√£o da classifica√ß√£o",
  "confidence": 0.95
}

Exemplo: "Quero odds do Flamengo vs Palmeiras"
Resposta: {"tipo_consulta": "odds_lookup", "query": "Flamengo vs Palmeiras odds", "explicacao": "Busca de odds para jogo espec√≠fico", "confidence": 0.95}

Se n√£o for poss√≠vel identificar, retorne: {"tipo_consulta": "general", "query": "", "explicacao": "Consulta geral", "confidence": 0.5}`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: prompt },
          { role: 'user', content: userMessage }
        ],
        max_tokens: 200,
        temperature: 0.1
      })

      const content = response.choices[0]?.message?.content || ''
      const result = JSON.parse(content)

      return {
        tipo_consulta: result.tipo_consulta || 'general',
        query: result.query || userMessage,
        explicacao: result.explicacao || 'Consulta n√£o classificada',
        confidence: result.confidence || 0.5
      }
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na interpreta√ß√£o de inten√ß√£o:', error)
      return {
        tipo_consulta: 'general',
        query: userMessage,
        explicacao: 'Erro na interpreta√ß√£o',
        confidence: 0.3
      }
    }
  }

  /**
   * Analisar confronto entre times
   */
  async getGameAnalysis(team1: string, team2: string): Promise<string> {
    const prompt = `Analise o confronto entre ${team1} e ${team2}. Considere:
- Hist√≥rico recente
- For√ßa do elenco atual
- Les√µes e desfalques
- Momento da temporada
- Motiva√ß√£o e objetivos

Forne√ßa uma an√°lise detalhada com probabilidades estimadas.`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.3
      })

      return response.choices[0]?.message?.content || 'N√£o foi poss√≠vel analisar o confronto.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na an√°lise do confronto:', error)
      throw error
    }
  }

  /**
   * Gerar resposta final com dados do Browserbase
   */
  async generateFinalResponse(
    userMessage: string, 
    browserbaseData: any, 
    context?: string
  ): Promise<string> {
    const systemPrompt = this.generateSystemPrompt(context)
    
    const userPrompt = `
Mensagem do usu√°rio: ${userMessage}

Dados reais obtidos via Browserbase:
${JSON.stringify(browserbaseData, null, 2)}

Gere uma resposta completa e profissional baseada nos dados reais fornecidos.
`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        max_tokens: 1500,
        temperature: 0.3
      })

      return response.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar uma resposta.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na gera√ß√£o da resposta:', error)
      return 'Desculpe, ocorreu um erro ao processar sua solicita√ß√£o.'
    }
  }

  /**
   * Gerar prompt do sistema
   */
  private generateSystemPrompt(context?: string): string {
    return `
Voc√™ √© o ScoutBet, o assistente de IA mais avan√ßado para apostas esportivas no Brasil.

### IDENTIDADE E PERSONALIDADE
- Especialista confi√°vel em apostas esportivas com conhecimento profundo
- Comunica√ß√£o clara, direta e sempre baseada em dados
- Tom profissional mas acess√≠vel, adaptando-se ao n√≠vel do usu√°rio
- Proativo em educar sobre gest√£o de risco e apostas respons√°veis

### RESPONSABILIDADES PRINCIPAIS
1. **AN√ÅLISE DE DADOS**: Interpretar odds, estat√≠sticas, tend√™ncias e padr√µes
2. **DETEC√á√ÉO DE VALOR**: Identificar oportunidades com valor positivo esperado
3. **GEST√ÉO DE RISCO**: Orientar sobre bankroll management e stakes apropriados
4. **EDUCA√á√ÉO**: Explicar conceitos de forma did√°tica e progressiva
5. **DISCLAIMER**: Sempre mencionar riscos e limita√ß√µes das apostas

### DIRETRIZES FUNDAMENTAIS
- Sempre cite fontes de dados quando dispon√≠vel
- Use probabilidades e estat√≠sticas para embasar an√°lises
- Seja transparente sobre limita√ß√µes e incertezas
- Adapte linguagem t√©cnica ao n√≠vel demonstrado pelo usu√°rio
- Priorize apostas de valor sobre "dicas quentes"
- Enfatize gest√£o de banca e apostas respons√°veis

### FORMATO DE RESPOSTA PADR√ÉO
Use sempre esta estrutura quando aplic√°vel:
üéØ RESPOSTA DIRETA (m√°ximo 2 linhas)
üìä AN√ÅLISE (dados e contexto relevantes)
üí° RECOMENDA√á√ÉO (a√ß√£o sugerida baseada na an√°lise)
‚ö†Ô∏è GEST√ÉO DE RISCO (stake sugerido e disclaimer)

### POL√çTICA DE DADOS
- APENAS DADOS REAIS obtidos via Browserbase
- NUNCA usar simula√ß√µes ou dados inventados
- Se dados indispon√≠veis: comunicar claramente e sugerir alternativas
- Browserbase √© o motor de busca, Perplexity AI apenas coordena e analisa

### CONTEXTO ESPEC√çFICO
${context || 'An√°lise geral de apostas esportivas'}

### EXEMPLOS DE RESPOSTAS PROFISSIONAIS

Para arbitragem:
"üéØ Encontrei 3 oportunidades de arbitragem com lucro garantido entre 2-5%.

üìä Dados coletados de 8 casas de apostas em tempo real:
- Flamengo vs Palmeiras: 2.3% de lucro garantido
- Real Madrid vs Barcelona: 1.8% de lucro garantido
- Manchester City vs Liverpool: 4.2% de lucro garantido

üí° Recomendo aproveitar a oportunidade do Manchester City vs Liverpool com stake de R$ 100 em cada casa.

‚ö†Ô∏è GEST√ÉO DE RISCO: Stake m√°ximo 2% do bankroll. Arbitragem √© livre de risco mas requer execu√ß√£o r√°pida."

Para value betting:
"üéØ Identifiquei 2 value bets com valor esperado positivo.

üìä An√°lise baseada em dados hist√≥ricos e odds atuais:
- Santos vs Corinthians: EV +8.5% (odds 2.15 vs probabilidade real 46%)
- Gr√™mio vs Internacional: EV +12.3% (odds 3.40 vs probabilidade real 29%)

üí° Recomendo apostar R$ 50 no Santos e R$ 30 no Gr√™mio.

‚ö†Ô∏è GEST√ÉO DE RISCO: Stakes baseados em 1-2% do bankroll. Value betting tem risco mas expectativa positiva a longo prazo."
`
  }

  /**
   * Analisar dados de arbitragem
   */
  async analyzeArbitrageData(data: any): Promise<string> {
    const prompt = `
Analise os seguintes dados de arbitragem e forne√ßa insights profissionais:

${JSON.stringify(data, null, 2)}

Forne√ßa:
1. Oportunidades identificadas
2. Percentuais de lucro
3. Recomenda√ß√µes de stake
4. Riscos e considera√ß√µes
`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: this.generateSystemPrompt('An√°lise de arbitragem') },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.2
      })

      return response.choices[0]?.message?.content || 'Erro na an√°lise de arbitragem.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na an√°lise de arbitragem:', error)
      return 'Erro ao analisar dados de arbitragem.'
    }
  }

  /**
   * Analisar dados de value betting
   */
  async analyzeValueBetData(data: any): Promise<string> {
    const prompt = `
Analise os seguintes dados de value betting e forne√ßa insights profissionais:

${JSON.stringify(data, null, 2)}

Forne√ßa:
1. Oportunidades de valor identificadas
2. C√°lculos de expected value
3. Recomenda√ß√µes de stake
4. An√°lise de risco
`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: this.generateSystemPrompt('An√°lise de value betting') },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.2
      })

      return response.choices[0]?.message?.content || 'Erro na an√°lise de value betting.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na an√°lise de value betting:', error)
      return 'Erro ao analisar dados de value betting.'
    }
  }

  /**
   * Analisar dados estat√≠sticos
   */
  async analyzeStatisticalData(data: any): Promise<string> {
    const prompt = `
Analise os seguintes dados estat√≠sticos e forne√ßa insights profissionais:

${JSON.stringify(data, null, 2)}

Forne√ßa:
1. Tend√™ncias identificadas
2. Insights estat√≠sticos
3. Recomenda√ß√µes de apostas
4. Limita√ß√µes dos dados
`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: this.generateSystemPrompt('An√°lise estat√≠stica') },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.2
      })

      return response.choices[0]?.message?.content || 'Erro na an√°lise estat√≠stica.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na an√°lise estat√≠stica:', error)
      return 'Erro ao analisar dados estat√≠sticos.'
    }
  }

  /**
   * Analisar dados de xG
   */
  async analyzeXGData(data: any): Promise<string> {
    const prompt = `
Analise os seguintes dados de Expected Goals (xG) e forne√ßa insights profissionais:

${JSON.stringify(data, null, 2)}

Forne√ßa:
1. An√°lise de xG vs gols reais
2. Oportunidades de over/under
3. Insights de performance
4. Recomenda√ß√µes de apostas
`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: this.generateSystemPrompt('An√°lise de xG') },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.2
      })

      return response.choices[0]?.message?.content || 'Erro na an√°lise de xG.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na an√°lise de xG:', error)
      return 'Erro ao analisar dados de xG.'
    }
  }

  /**
   * Gerar relat√≥rio executivo
   */
  async generateExecutiveReport(data: any): Promise<string> {
    const prompt = `
Gere um relat√≥rio executivo profissional baseado nos seguintes dados:

${JSON.stringify(data, null, 2)}

O relat√≥rio deve incluir:
1. Resumo executivo
2. Principais descobertas
3. Oportunidades identificadas
4. Recomenda√ß√µes estrat√©gicas
5. An√°lise de risco
6. Pr√≥ximos passos
`

    try {
      const response = await this.callAPI({
        model: 'sonar',
        messages: [
          { role: 'system', content: this.generateSystemPrompt('Relat√≥rio executivo') },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1500,
        temperature: 0.3
      })

      return response.choices[0]?.message?.content || 'Erro na gera√ß√£o do relat√≥rio.'
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro na gera√ß√£o do relat√≥rio:', error)
      return 'Erro ao gerar relat√≥rio executivo.'
    }
  }

  /**
   * Testar conex√£o com Perplexity
   */
  async testConnection(): Promise<boolean> {
    try {
      const response = await this.callAPI({
        model: 'sonar-small',
        messages: [
          { role: 'user', content: 'Teste de conex√£o' }
        ],
        max_tokens: 10
      })

      return response.choices.length > 0
    } catch (error) {
      console.error('‚ùå [PERPLEXITY] Erro no teste de conex√£o:', error)
      return false
    }
  }

  /**
   * Obter estat√≠sticas de uso
   */
  async getUsageStats(): Promise<{
    totalTokens: number
    promptTokens: number
    completionTokens: number
    requests: number
  }> {
    // Em uma implementa√ß√£o real, voc√™ manteria essas estat√≠sticas
    return {
      totalTokens: 0,
      promptTokens: 0,
      completionTokens: 0,
      requests: 0
    }
  }
}

// Inst√¢ncia singleton
export const perplexityAI = new PerplexityAIIntegration()